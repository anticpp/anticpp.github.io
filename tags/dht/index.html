<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Tag: dht | supergui</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="旗帜鲜明的站在C++的对立面">
<meta property="og:type" content="website">
<meta property="og:title" content="supergui">
<meta property="og:url" content="http://anticpp.github.io/tags/dht/index.html">
<meta property="og:site_name" content="supergui">
<meta property="og:description" content="旗帜鲜明的站在C++的对立面">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="supergui">
<meta name="twitter:description" content="旗帜鲜明的站在C++的对立面">
  
    <link rel="alternate" href="/atom.xml" title="supergui" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">supergui</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">迁于乔木，出自幽谷</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Suche"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://anticpp.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-dht" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/04/17/dht/" class="article-date">
  <time datetime="2018-04-17T13:03:24.000Z" itemprop="datePublished">2018-04-17</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/04/17/dht/">DHT</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-背景"><a href="#1-背景" class="headerlink" title="1. 背景"></a>1. 背景</h2><p>BT作为历史上最成功的P2P文件系统，已经在全球实现了彻底的去中心化。BT的P2P网络，不依赖任何机构或者中心依然能够很好的运行。<br>这里面，最关键的设计是引入了DHT。这里我们主要介绍一下为什么要引入DHT，以及DHT的基本原理。</p>
<p>BT作为一种P2P系统，面临<strong><em>资源索引</em></strong>问题，简单来说<strong><em>资源索引</em></strong>维护资源(resource)当前有哪些节点(peer)也在同时下载的关系。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">res0 -&gt; peerA,peerB,...</span><br><span class="line">res1 -&gt; peerC,peerD,...</span><br><span class="line"></span><br><span class="line">                         ------------------------------</span><br><span class="line">              Index ---&gt; | res0 | res1 | ...          |</span><br><span class="line">                         ------------------------------</span><br><span class="line">                            |      |</span><br><span class="line">                           \|/    \|/</span><br><span class="line">                         ------- -------</span><br><span class="line">                         |peerA| |peerC|</span><br><span class="line">                         ------- -------</span><br><span class="line">                         |peerB| |peerD|</span><br><span class="line">                         ------- -------</span><br></pre></td></tr></table></figure>
<h2 id="2-中心化"><a href="#2-中心化" class="headerlink" title="2. 中心化"></a>2. 中心化</h2><p>BT的数据传输本身是去中心化的，每一个peer会同时从网络上搜索到的其它peer进行数据传输。<br>但是<strong><em>资源索引</em></strong>一开始还是中心化的解决方案，就是Tracker。虽然网络上有很多提供Tracker的服务，每一个客户端也可以设置若干个Tracker，但是Tracker依然是一个中心化的服务。</p>
<p>Tracker原理很简单，提供了上报和查询服务。如下图：正在下载某一个资源(res)的BT客户端peer2把资源上报给Tracker。下载资源的BT客户端(peer1)可以到Tracker查询时下载这个资源的peer2。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">           --------------    -----------------------------------</span><br><span class="line">      |---&gt;| Tracker    | -- |           Index                 |</span><br><span class="line">      |    --------------    -----------------------------------</span><br><span class="line">      |     |         /|\   </span><br><span class="line">      |     |          |</span><br><span class="line">      |     |          |</span><br><span class="line">query |     |resp      |</span><br><span class="line">      |     |(peer2)   |</span><br><span class="line">      |     |          |    report res</span><br><span class="line">      |     |          |----------------</span><br><span class="line">      |    \|/                         |</span><br><span class="line">   -----------                     ---------</span><br><span class="line">   |  peer1  |                     | peer2 |</span><br><span class="line">   -----------                     ---------</span><br></pre></td></tr></table></figure>
<p>Tracker提供了一种简单高效的方案，解决了资源索引的问题。缺点是一旦Tracker不可用，BT的P2P网络也就随之瘫痪(可以参考海盗湾事件)。这是所有中心化服务必将面临的问题，为了让整个P2P网络更加健壮，需要探索一个去中心化的实现。</p>
<h2 id="3-去中心化"><a href="#3-去中心化" class="headerlink" title="3. 去中心化"></a>3. 去中心化</h2><p>考虑没有中心化的Tracker，我们需要一个去中心化的方式，把资源的索引存储(sharding)到全网的节点，并且能高效的查询。</p>
<h3 id="3-1-全量"><a href="#3-1-全量" class="headerlink" title="3.1 全量"></a>3.1 全量</h3><p>最简单的办法，就是让每一个Node(节点)都维护一个全量的索引，相当于每个Node都是一个Tracker节点。</p>
<blockquote>
<p>注意：我们需要区分一下Node和Peer的概念，以下是DHT的papper的描述<br>A “peer” is a client/server listening on a TCP port that implements the BitTorrent protocol. A “node” is a client/server listening on a UDP port implementing the distributed hash table protocol. </p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">--------------    -----------------------------------</span><br><span class="line">| Node0      | -- |           Index                 |</span><br><span class="line">--------------    -----------------------------------</span><br><span class="line"></span><br><span class="line">--------------    -----------------------------------</span><br><span class="line">| Node1      | -- |           Index                 |</span><br><span class="line">--------------    -----------------------------------</span><br><span class="line">    </span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line">--------------    -----------------------------------</span><br><span class="line">| NodeN      | -- |           Index                 |</span><br><span class="line">--------------    -----------------------------------</span><br></pre></td></tr></table></figure>
<p>这种方案有几个明显的问题</p>
<ol>
<li>每个索引的变更需要扩散到全网，效率太差</li>
<li>海量的索引，每个单点都需要全量存储，代价太大</li>
</ol>
<h3 id="3-2-Sharding"><a href="#3-2-Sharding" class="headerlink" title="3.2 Sharding"></a>3.2 Sharding</h3><p>基本的思路是，我们需要把索引数据按照<strong><em>一定规则</em></strong>分布(sharding)到全网的节点。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">    -----------       -----------     -----------                   -----------</span><br><span class="line">    |  Node0  |       |  Node1  |     |  Node2  |       ...         |  NodeN  |</span><br><span class="line">    -----------       -----------     -----------                   -----------</span><br><span class="line">       /|\                 /|\            /|\                            /|\</span><br><span class="line">        |--------           |              |                              |</span><br><span class="line">                 |          |              |                              |</span><br><span class="line">            -----------------------------------------------------------------------</span><br><span class="line">Index ----&gt; |  shard0    |  shard1    |   shard2     |  ...      |    shardN      |</span><br><span class="line">            -----------------------------------------------------------------------</span><br></pre></td></tr></table></figure>
<p>一致性Hash是一种常用的办法，首先把Node散列(hash<nodeid>)到一个整数的空间，这样每一个Node负责一个范围段的索引。<br>同样，我们可以把资源也计算一个整数的hash。<br>例如，NodeA负责范围<code>[i, j)</code>的范围，那么如果索引按照分布规则在范围内，那么该索引就由NodeA负责存储。</nodeid></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// NodeA covers [i, j).</span><br><span class="line">// Use hash(resource) to caculate resource.</span><br><span class="line">if i &lt; hash(resource) &lt; j &#123;</span><br><span class="line">    store(resource, NodeA) </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里盗用一个网上的一致性Hash图片，具体的算法这里就不重复介绍了。</p>
<p><img src="/images/dht-constant-hash.jpg" alt=""></p>
<p>一致性Hash解决了sharding的问题，但是一致性Hash引入了Hash环状态。在系统中如何维护Hash状态数据，跟如何维护资源索引面临一样的问题。</p>
<p>我们需要彻底解决状态数据的问题，才能真正实现去中心化。</p>
<h2 id="4-DHT"><a href="#4-DHT" class="headerlink" title="4. DHT"></a>4. DHT</h2><p>DHT(Distributed Hash Table)，就是分布式Hash table。实际上也是Sharding的一种实现方法，DHT可以看作是一致性Hash的基础上的改进。一致性Hash算法的问题是Hash环的状态数据，只要我们能设计出一种关于索引分布规则的去中心化的<strong><em>共识机制</em></strong>，我们并不需要去维护一个Hash环。关于DHT的比较完整的介绍，可以参考<a href="http://www.bittorrent.org/beps/bep_0005.html" target="_blank" rel="external">DHT Protocol</a>。</p>
<p>DHT设计了这样一种去中心化的<strong><em>共识机制</em></strong>：索引信息应该存储到到距离目标<strong><em>更近</em></strong>的节点。</p>
<h3 id="4-1-Hash"><a href="#4-1-Hash" class="headerlink" title="4.1 Hash"></a>4.1 Hash</h3><p>DHT网络中每个节点的NodeID就是一个hash值，每个资源也有一个hash。</p>
<h3 id="4-2-距离"><a href="#4-2-距离" class="headerlink" title="4.2 距离"></a>4.2 距离</h3><p>用来计算2个hash的距离，Node和Node之间可以有距离，Node和资源之间也可以有距离。要注意的是，这个距离并不是实际意义上的距离，只是一个算法上的需要。</p>
<h3 id="4-3-Routing-table"><a href="#4-3-Routing-table" class="headerlink" title="4.3 Routing table"></a>4.3 Routing table</h3><p>DHT网络中每个Node都维护一个Routing table（路由表），这是DHT的核心部分，它保存本节点和网络中一小部分节点信息。每一个节点，都能够提供查询接口，并且能够返回距离目标hash<strong><em>更近</em></strong>的节点。这样通过网络中递归查询Routihng table，可以不断的趋向<strong><em>更近</em></strong>。IPFS把这个过程总结为<a href="https://github.com/libp2p/specs/blob/master/4-architecture.md#41-peer-routing" target="_blank" rel="external">Peer Routing</a>的过程。我们可以用Peer routing解决DHT的<strong><em>共识机制</em></strong>。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">                   ---------------------------------------------</span><br><span class="line">Routing table --&gt;  | NodeInfo0 | NodeInfo1 | ...   | NodeInfoN |</span><br><span class="line">                   ---------------------------------------------</span><br></pre></td></tr></table></figure>
<p>我们以查询资源为例，一个典型的Query Resource过程：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">1 ) client需要查找目标资源hash，先到Node0进行查询。</span><br><span class="line">2 ) 如果Node0本地有这个hash的索引，则返回结果</span><br><span class="line">3 ) 如果Node0本地没有这个hash的索引，Node0从自己的Routing table查找离目标hash更近的节点，例如Node1和Node2</span><br><span class="line">4 ) client对Node1和Node2重复过程1的查询，直到有查询到有结果</span><br><span class="line"></span><br><span class="line">           1) query hash       -----------</span><br><span class="line">client  --------------------&gt;  |         |</span><br><span class="line">        &lt;-------------------   |  Node0  |</span><br><span class="line">           2 ) Resource        |         |</span><br><span class="line">           3 ) Node1,Node2     -----------</span><br><span class="line"></span><br><span class="line">           4 ) query hash      -----------</span><br><span class="line">        --------------------&gt;  |  Node1  |</span><br><span class="line">                               -----------</span><br><span class="line"></span><br><span class="line">           4 ) query hash      -----------</span><br><span class="line">        --------------------&gt;  |  Node2  |</span><br><span class="line">                               -----------</span><br></pre></td></tr></table></figure></p>
<h2 id="5-Kademlia"><a href="#5-Kademlia" class="headerlink" title="5. Kademlia"></a>5. Kademlia</h2><p>DHT有很多不同的实现，这里主要介绍Kademlia，一般我们叫KAD。现在大部分的DHT都是基于KAD实现，或者KAD的一些改进。<br>KAD使用k-bucket(k桶)实现Routing table，能实现log2(N)的查找效率。假设1000000节点的规模的网络，可以最多20次查询能够完成全网节点的查询。</p>
<p>关于KAD的实现有很多细节，我们这里着重介绍为什么k-bucket能实现log2(N)的查找效率。</p>
<h3 id="5-1-距离"><a href="#5-1-距离" class="headerlink" title="5.1 距离"></a>5.1 距离</h3><p>KAD使用XOR(按位异或)对两个hash进行距离计算，为什么要使用异或？我们后面结合k桶可以看到，这是经过精心设计的算法。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">distance(A, B) = A xor B</span><br></pre></td></tr></table></figure>
<h3 id="5-2-Routing-table"><a href="#5-2-Routing-table" class="headerlink" title="5.2 Routing table"></a>5.2 Routing table</h3><p>KAD使用K桶(K-bucket)实现Routing table，K桶实际上是一个hash table。Hash table的大小取决于我们使用hash的位数，因为KAD使用sha1做hash算法，sha1的hash结果为160位，所以KAD的K桶大小为160。</p>
<p>那么K是什么意思呢，KAD限制了每个桶最多能存储K个节点信息，所以叫K桶。默认的KAD实现K一般为8。</p>
<blockquote>
<p>实际的实现是K桶大小初始化为1，随着每个桶的节点数量超过K，K桶会进行对半分裂。由于不是关键点，我们这里就不详细介绍。</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">               -----------------------------------------------------------------------</span><br><span class="line">K-bucket ---&gt;  |  0  |  1  |  2  |                  ...                 | 158  | 159 |</span><br><span class="line">               -----------------------------------------------------------------------</span><br><span class="line">                  |</span><br><span class="line">                 \|/</span><br><span class="line">               ------------</span><br><span class="line">            -- | NodeInfo |</span><br><span class="line">            |  ------------</span><br><span class="line">            |  | NodeInfo |</span><br><span class="line">         K &lt;   ------------</span><br><span class="line">            |  |   ...    |</span><br><span class="line">            |  ------------</span><br><span class="line">            -- | NodeInfo |</span><br><span class="line">               ------------</span><br></pre></td></tr></table></figure>
<h3 id="5-3-K桶算法"><a href="#5-3-K桶算法" class="headerlink" title="5.3 K桶算法"></a>5.3 K桶算法</h3><p>那么，一个NodeInfo应该放到哪个桶呢。KAD的算法是，越小(具体实现也可能是越大，算法本质都一样)的桶存储的NodeInfo距离本节点的ID越远，并且每递增一个桶，距离折半。可以用按bit前缀匹配来实现，简单来说，第N个桶存储的节点NodeID与当前节点的NodeID前N-1位相同，第N位不同。</p>
<p>上面的描述还是有点晦涩，大家可以简单推算一下(XOR计算距离)，第0个桶上面的NodeInfo的ID所有的bit跟本节点ID都不一样（距离2^N，最远），最后一个桶的NodeInfo的ID只有最后一个bit跟本节点ID不一样（距离2^0=1）。</p>
<p>按照这个算法，有几个比较明显的结论是：</p>
<ol>
<li>越大的桶存储的是离本节点越<strong><em>近</em></strong>的节点信息(XOR计算距离)</li>
<li>第N+1个桶存储的节点，比第N个桶存储的节点，距离本节点近了<strong><em>一半</em></strong>。也就是每递增一个桶，节点数量<strong><em>折半</em></strong>。</li>
<li>桶内所有的节点之间的距离，都一定比桶内节点跟本节点的距离，至少更近<strong><em>一半</em></strong>。(桶内节点跟本节点第N位不同，那么这些节点之间的第N位一定相同，也就是这些节点之间的前N位都相同)</li>
</ol>
<p>我门用一个K桶大小为4的例子说明:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">// 假如节点0000保存了全部节点信息，实际上网络很大的时候一个节点的K桶只会保存一部分节点信息</span><br><span class="line">// 下面为节点0000上的K桶</span><br><span class="line"></span><br><span class="line">          -------------------------</span><br><span class="line">          |  0  |  1  |  2  |  3  |</span><br><span class="line">          -------------------------</span><br><span class="line">           1000  0100  0010  0001</span><br><span class="line">           1001  0101  0011</span><br><span class="line">           1010  0110  </span><br><span class="line">           1011  0111</span><br><span class="line">           1100</span><br><span class="line">           1101</span><br><span class="line">           1110</span><br><span class="line">           1111</span><br></pre></td></tr></table></figure>
<p>可以看到：</p>
<ol>
<li>第1个桶节点和本节点距离，比第0个桶节点和本节点的距离，更近。(例如 (0100 xor 0000 = 0100) &lt; (1000 xor 0000 = 1000) )</li>
<li>第1个桶的节点数量，是第0个桶节点数量的一半。也就是越大的桶，节点数量是折半。</li>
<li>第0个桶，内部的节点距离，会比本节点距离至少更近<strong><em>一半</em></strong>。(例如 1000 xor 1001 = 0001, 1000 xor 0000 = 1000)</li>
</ol>
<h3 id="5-4-折半效率"><a href="#5-4-折半效率" class="headerlink" title="5.4 折半效率"></a>5.4 折半效率</h3><p>所以，为什么KAD能够实现log2(N)的折半查找效率呢。</p>
<p>假如我们要查找/存储的目标为资源target，第一轮查询我们到节点Node0进行查询，Node0进行的操作为：</p>
<ol>
<li>如果Node0拥有target资源，则返回</li>
<li>否则，计算target和Node0的距离所对应的K桶，例如为N</li>
<li>返回第N个桶的K个新节点信息</li>
</ol>
<p>考虑第3)步，返回给客户端的这K个新节点，我们很容易得出一个结论：target和新节点的距离，至少比和Node0的距离<strong><em>近一半</em></strong>。</p>
<blockquote>
<p>由于target和Node0计算距离定位到第N个桶，也就是target和Node0也是前缀关系，前N-1位相同，第N位不同。<br>再由于，”桶内所有的节点之间的距离，都一定比桶内节点跟本节点的距离，至少更近<strong><em>一半</em></strong>“。</p>
</blockquote>
<p>客户端拿到离目标更近一半的新节点，继续进行下一轮查询，每递归一轮查找都能<strong><em>折半</em></strong>趋近。</p>
<h2 id="6-结论"><a href="#6-结论" class="headerlink" title="6 结论"></a>6 结论</h2><p>虽然我们这里忽略了很多DHT和KAD的实现细节，但是可以看到KAD通过K桶的Peer routing，能够实现折半效率的Peer routing。从而，我们可以通过Peer routing查找/存储到距离目标<strong><em>最近</em></strong>的节点，实现一个<strong><em>共识机制</em></strong>。</p>
<p>DHT作为去中心化的实现，相对中心化的Tracker，牺牲的是效率(慢扩散查找)和一致性(最终一致)，换来的是网络的健壮性。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://anticpp.github.io/2018/04/17/dht/" data-id="cklzykfcl00045zp3qi8g82ph" class="article-share-link">Teilen</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/dht/">dht</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/p2p/">p2p</a></li></ul>

    </footer>
  </div>
  
</article>


  


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/IP/">IP</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/dht/">dht</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/go/">go</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/media/">media</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/meeting/">meeting</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/mq/">mq</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/network/">network</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/openssl/">openssl</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/p2p/">p2p</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/programing-lanuage/">programing lanuage</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/security/">security</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ssl-tls/">ssl/tls</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/tools/">tools</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/IP/" style="font-size: 10px;">IP</a> <a href="/tags/dht/" style="font-size: 10px;">dht</a> <a href="/tags/go/" style="font-size: 20px;">go</a> <a href="/tags/media/" style="font-size: 10px;">media</a> <a href="/tags/meeting/" style="font-size: 10px;">meeting</a> <a href="/tags/mq/" style="font-size: 10px;">mq</a> <a href="/tags/network/" style="font-size: 15px;">network</a> <a href="/tags/openssl/" style="font-size: 10px;">openssl</a> <a href="/tags/p2p/" style="font-size: 10px;">p2p</a> <a href="/tags/programing-lanuage/" style="font-size: 15px;">programing lanuage</a> <a href="/tags/python/" style="font-size: 10px;">python</a> <a href="/tags/security/" style="font-size: 10px;">security</a> <a href="/tags/ssl-tls/" style="font-size: 10px;">ssl/tls</a> <a href="/tags/tools/" style="font-size: 20px;">tools</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archiv</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/03/">March 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/05/">May 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/04/">April 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">November 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">March 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">February 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">letzter Beitrag</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/03/04/message-queue/">Message queue</a>
          </li>
        
          <li>
            <a href="/2018/05/11/gopher-2018/">Gopher 2018 shanghai memo</a>
          </li>
        
          <li>
            <a href="/2018/05/05/cpp-virtual-vs-go-interface/">Go interface internal</a>
          </li>
        
          <li>
            <a href="/2018/05/03/private-addr/">IPv4 private address</a>
          </li>
        
          <li>
            <a href="/2018/04/17/dht/">DHT</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2021 supergui@live.cn<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>




  </div>
</body>
</html>